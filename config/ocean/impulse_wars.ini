[base]
package = ocean
env_name = impulse_wars
policy_name = ImpulseWarsPolicy
rnn_name = ImpulseWarsLSTM
vec = multiprocessing
max_suggestion_cost = 10_800

[policy]
cnn_channels = 64
input_size = 512
hidden_size = 512

# These must match what's set in env below
discretize_actions = True
num_drones = 2
# Needs to be False for rendering to go at a normal speed
is_training = True

[env]
num_envs = 128
num_drones = 2
num_agents = 1
enable_teams = False
sitting_duck = False
discretize_actions = True
is_training = True
render = False

[train]
checkpoint_interval = 250
num_envs = 16
num_workers = 16
env_batch_size = 4

compile = False
compile_mode = reduce-overhead
compile_fullgraph = False
device = cuda

[sweep]
method = protein 
name = sweep

[sweep.metric]
goal = maximize
name = score
min = 0.0
max = 1.0

[sweep.env.num_envs]
distribution = uniform_pow2
min = 16
max = 512
mean = 128
scale = auto

[sweep.train.total_timesteps]
distribution = log_normal
min = 250_000_000
max = 1_500_000_000
mean = 500_000_000
scale = time

[sweep.train.batch_size]
distribution = uniform_pow2
min = 65_536
max = 1_048_576
mean = 262_144
scale = auto

[sweep.train.bptt_horizon]
distribution = uniform_pow2
min = 64
max = 512
mean = 256
scale = auto

[sweep.train.minibatch_size]
distribution = uniform_pow2
min = 1024
max = 262_144
mean = 16_384
scale = auto

[sweep.train.learning_rate]
distribution = log_normal
min = 0.00001
mean = 0.001
max = 0.1
scale = 0.5

[sweep.train.ent_coef]
distribution = log_normal
min = 0.000001
mean = 0.001
max = 0.2
scale = auto

[sweep.train.gamma]
distribution = logit_normal
min = 0.8
mean = 0.98
max = 0.99999
scale = auto

[sweep.train.gae_lambda]
distribution = logit_normal
min = 0.6
mean = 0.93
max = 0.995
scale = auto

[sweep.train.vf_coef]
distribution = uniform
min = 0.0
max = 5.0
mean = 1.0
scale = auto

[sweep.train.max_grad_norm]
distribution = uniform
min = 0.0
mean = 1.0
max = 5.0
scale = auto
