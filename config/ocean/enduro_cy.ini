[base]
package = ocean
env_name = enduro_cy
policy_name = Policy
rnn_name = None

[train]
total_timesteps = 300_000
learning_rate = 0.017
num_envs = 2
num_workers = 2
env_batch_size = 2
batch_size = 512
minibatch_size = 512
bptt_horizon = 4
device = cpu


; batch_size = 16384
; minibatch_size = 4096
; update_epochs = 6
; bptt_horizon = 8
; learning_rate = 0.0003495115734491776
; gae_lambda = 0.5996818325556474
; gamma = 0.9895491287086732
; ent_coef = 0.0021720638001863288
; clip_coef = 0.7140062837950062
; vf_clip_coef = 0.02629607191897852
; vf_coef = 0.9842251826587504
; max_grad_norm = 0.8422542810440063

[env]
frameskip = 4
repeat_action_probability = 0.0