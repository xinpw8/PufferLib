[base]
package = ocean
env_name = spaces_cy

[train]
total_timesteps = 100_000_000

num_envs = 2
num_workers = 2
env_batch_size = 1
device = cpu
checkpoint_interval = 50

batch_size = 65536
minibatch_size = 8192

anneal_lr = false
bptt_horizon = 8
clip_coef = 0.10944657790889258
clip_vloss = true
ent_coef = 0.007053685467058537
gae_lambda = 0.9462698603300184
gamma = 0.9348332880396868
learning_rate = 0.00031617638387428646
max_grad_norm = 0.7705206871032715
norm_adv = true
update_epochs = 3
vf_clip_coef = 0.06908694316063399
vf_coef = 0.46530283591543886

[sweep.metric]
goal = maximize
name = environment/episodic_return