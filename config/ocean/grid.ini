[base]
package = ocean
env_name = puffer_grid
vec = multiprocessing
policy_name = Policy
rnn_name = Recurrent

[policy]
hidden_size = 512

[rnn]
input_size = 512
hidden_size = 512

[env]
max_size = 31
num_envs = 2048
num_maps = 8192

[train]
total_timesteps = 180_000_000
checkpoint_interval = 1000
learning_rate = 0.0025
gamma = 0.9944336976183826
gae_lambda = 0.9474288929489364
ent_coef = 0.00001

num_envs = 1
num_workers = 1
env_batch_size = 1
update_epochs = 1
minibatch_size = 8192

[sweep]
method = protein
name = sweep

[sweep.metric]
goal = maximize
name = score 
min = 0
max = 1

[sweep.train.total_timesteps]
distribution = log_normal
min = 5e7
max = 2e8
mean = 1e8
scale = auto

[sweep.train.e3b_coef]
distribution = logit_normal
min = 0.0001
max = 0.99
mean = 0.001
scale = auto

[sweep.train.e3b_lambda]
distribution = log_normal
min = 0.01
max = 10.0
mean = 0.1
scale = auto

[sweep.train.e3b_norm]
distribution = log_normal
min = 0.0001
max = 0.1
mean = 0.001
scale = auto

