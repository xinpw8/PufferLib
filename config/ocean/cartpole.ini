[base]
package = ocean
env_name = puffer_cartpole
vec = multiprocessing
policy_name = Policy
rnn_name = Recurrent

[env]
num_envs = 4096 # 2048 # 1024 # 512 # 256 # 2048

[train]
anneal_lr = True
batch_size = 262144 # 16384 # 8192 # 65536 # 16384
bptt_horizon = 32 # 16
checkpoint_interval = 50
clip_coef = 0.2
clip_vloss = True
compile = False
compile_mode = reduce-overhead
cpu_offload = False
data_dir = experiments
device = cuda
ent_coef = 0.0097648317226976 # 0.00003900277311898606 # 0.01
env_batch_size = 1
gae_lambda = 0.8565811585596427 # 0.8175218896853491 # 0.95
gamma = 0.9660548302390047 # 0.95 # 0.9 # 0.99
learning_rate = 0.00025 # 0.0007705882248800876 # 0.00025
max_grad_norm = 1.877352899116142 # 0.5
minibatch_size = 8192 # 256 # 512 # 1024
norm_adv = True
num_envs = 1
num_workers = 1
seed = 1
torch_deterministic = True
total_timesteps = 150000000 # 1300000
update_epochs = 1
vf_clip_coef = 0.2
vf_coef = 0.699137796315858 # 0.9 # 0.5
zero_copy = True

[sweep]
method = protein
name = sweep

[sweep.metric]
goal = maximize
name = episode_length
min = 0
max = 205

[sweep.train.total_timesteps]
distribution = log_normal
min = 1e6
max = 1e7
mean = 5e6
scale = 0.5

[sweep.train.gamma]
distribution = log_normal
min = 0.9
max = 0.999
mean = 0.97

[sweep.train.gae_lambda]
distribution = log_normal
min = 0.7
max = 0.999
mean = 0.95

[sweep.train.learning_rate]
distribution = log_normal
min = 0.0001
max = 0.001
mean = 0.00025
scale = 0.5

[sweep.train.batch_size]
min = 32768
max = 131072
mean = 65536
scale = 0.5

[sweep.train.minibatch_size]
min = 512
max = 2048
mean = 1024
scale = 0.5
