[base]
package = ocean
env_name = my_enduro_clone 
policy_name = Policy
rnn_name = Recurrent

[env]
num_envs = 4096

[train]
total_timesteps = 50_000_000_000
checkpoint_interval = 50
num_envs = 1
num_workers = 1
env_batch_size = 1
batch_size = 131072
update_epochs = 1
minibatch_size = 8192
bptt_horizon = 16
clip_coef = 0.3635978991022696
vf_clip_coef = 0.0830793239879089
vf_coef = 0.7648460021482193
ent_coef = 0.01533195510726322
gae_lambda = 0.6554736614285002
gamma = 0.934191000720247
learning_rate = 0.0010998279291254986 # 0.0011998279291254986
max_grad_norm = 0.3987805843353271
anneal_lr = False
device = cuda

; max settings below
; [train]
; total_timesteps = 3_300_000
; learning_rate = 0.017
; num_envs = 131072
; num_workers = 2
; env_batch_size = 65536
; batch_size = 65536
; minibatch_size = 65536
; bptt_horizon = 4
; update_epochs = 4
; device = cpu