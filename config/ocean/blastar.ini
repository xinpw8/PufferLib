[base]
package = ocean
env_name = puffer_blastar 
policy_name = Policy
rnn_name = Recurrent

[env]
num_envs = 4096

[train]
anneal_lr = False
batch_size = 131072 # 65536
bptt_horizon = 8
checkpoint_interval = 100
clip_coef = 0.2
clip_vloss = True
compile = False
compile_mode = reduce-overhead
cpu_offload = False
data_dir = experiments
device = cuda
ent_coef = 0.002511261007200052
env_batch_size = 1
gae_lambda = 0.9212875655241286
gamma = 0.9410283509696092
learning_rate = 0.0010700459984905535
max_grad_norm = 0.9702296257019044
minibatch_size = 4096
norm_adv = True
num_envs = 1
num_workers = 1
torch_deterministic = True
total_timesteps = 800000000
update_epochs = 1
vf_clip_coef = 0.2
vf_coef = 0.47285471525325906
zero_copy = True

[sweep.metric]
name = environment/enemy_crossed_screen
goal = minimize

[sweep.parameters.train.parameters.batch_size]
distribution = uniform
min = 65536
max = 524288

[sweep.parameters.train.parameters.minibatch_size]
distribution = uniform
min = 8192
max = 65536

[sweep.parameters.train.parameters.total_timesteps]
distribution = uniform
min = 10_000_000
max = 100_000_000
