[base]
package = None
env_name = None
policy_name = Policy
rnn_name = None
max_suggestion_cost = 3600

[env]
[policy]
[rnn]

[train]
seed =  1
torch_deterministic = True
cpu_offload = False
device = cuda
total_timesteps = 10_000_000
learning_rate = 2.5e-4
anneal_lr = True
gamma = 0.99
gae_lambda = 0.95
update_epochs = 4
norm_adv = True
clip_coef = 0.1
clip_vloss = True
vf_coef = 0.5
vf_clip_coef = 0.1
max_grad_norm = 0.5
ent_coef = 0.01
target_kl = None

num_envs = 8
num_workers = 8
env_batch_size = None
zero_copy = True
data_dir = experiments
checkpoint_interval = 200
batch_size = 1024
minibatch_size = 512
bptt_horizon = 16
compile = False
compile_mode = reduce-overhead

[sweep]
method = random
name = sweep

[sweep.metric]
goal = maximize
name = score 

[sweep.env.num_envs]
distribution = uniform_pow2
min = 256
max = 4096
mean = 1024
scale = 0.5

[sweep.train.total_timesteps]
distribution = log_normal
min = 5e7
max = 1e10
mean = 1e8
scale = 0.5

[sweep.train.batch_size]
distribution = uniform_pow2
min = 4096
max = 262144
mean = 65536
scale = 0.25

#[sweep.train.num_minibatches]
#distribution = uniform_pow2
#min = 1
#max = 8
#mean = 4
#scale = 0.5

[sweep.train.learning_rate]
distribution = log_normal
min = 0.00001
mean = 0.005
max = 0.05
scale = 0.5

[sweep.train.ent_coef]
distribution = log_normal
min = 0.00001
mean = 0.005
max = 0.05
scale = 0.5

[sweep.train.gamma]
distribution = logit_normal
min = 0.8
mean = 0.98
max = 0.995
scale = 0.5

[sweep.train.gae_lambda]
distribution = logit_normal
min = 0.7
mean = 0.95
max = 0.995
scale = 0.5

[sweep.train.update_epochs]
distribution = int_uniform
min = 1
max = 4
mean = 1
scale = 0.5

#[sweep.train.vf_coef]
#distribution = uniform
#min = 0.0
#max = 1.0

#[sweep.train.max_grad_norm]
#distribution = uniform
#min = 0.0
#max = 10.0

[sweep.train.bptt_horizon]
distribution = uniform_pow2
min = 1
max = 32
mean = 16
scale = 0.25
