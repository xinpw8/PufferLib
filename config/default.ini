[base]
package = None
env_name = None
vec = native
policy_name = Policy
rnn_name = None
max_suggestion_cost = 3600

[workspace]
name = pufferai 
project = ablations

[env]
[policy]
[rnn]

[train]
seed = 0
torch_deterministic = True
cpu_offload = False
device = cuda
optimizer = adam
scheduler = cosine
anneal_lr = True
precision = float32
total_timesteps = 10_000_000
learning_rate = 0.025
gamma = 0.995
gae_lambda = 0.85
update_epochs = 1
norm_adv = True
clip_coef = 0.1
clip_vloss = True
vf_coef = 2.0
vf_clip_coef = 0.1
max_grad_norm = 0.5
ent_coef = 0.01
target_kl = None
adam_beta1 = 0.9
adam_beta2 = 0.999
adam_eps = 1e-12

num_envs = 2
num_workers = 2
env_batch_size = 1
zero_copy = True
data_dir = experiments
checkpoint_interval = 200
batch_size = 524288
minibatch_size = 8192
# Accumulate gradients above this size
max_minibatch_size = 16384
bptt_horizon = 64
compile = False
compile_mode = reduce-overhead
compile_fullgraph = True

use_e3b = False
e3b_coef = 0.01
e3b_norm = 0.001
e3b_lambda = 10.0

use_diayn = False
diayn_archive = 8
diayn_loss_coef = 1.0
diayn_coef = 0.1

use_p3o = False
p3o_horizon = 128
puf = 0.0

[sweep]
method = protein 
name = sweep

[sweep.metric]
goal = maximize
name = score 
min = 0
max = 1

[sweep.env.num_envs]
distribution = uniform_pow2
min = 64
max = 4096
mean = 1024
scale = auto
#scale = 0.5

#[sweep.policy.hidden_size]
#distribution = uniform_pow2
#min = 32
#max = 1024
#mean = 128
#scale = auto

[sweep.train.total_timesteps]
distribution = log_normal
min = 5e7
max = 1e10
mean = 1e8
scale = time

[sweep.train.batch_size]
distribution = uniform_pow2
min = 32768
max = 1048576
mean = 262144
scale = auto

[sweep.train.minibatch_size]
distribution = uniform_pow2
min = 1024
max = 32768
mean = 8192
scale = auto

[sweep.train.learning_rate]
distribution = log_normal
min = 0.00001
mean = 0.01
max = 0.1
scale = 0.5

[sweep.train.ent_coef]
distribution = log_normal
min = 0.00001
mean = 0.01
max = 0.2
scale = auto

[sweep.train.gamma]
distribution = logit_normal
min = 0.8
mean = 0.98
max = 0.9999
scale = auto
#scale = 0.5

[sweep.train.gae_lambda]
distribution = logit_normal
min = 0.6
mean = 0.95
max = 0.995
scale = auto
#scale = 0.5

[sweep.train.update_epochs]
distribution = int_uniform
min = 1
max = 4
mean = 1
scale = 1.0

[sweep.train.vf_coef]
distribution = uniform
min = 0.0
max = 5.0
mean = 1.0
scale = auto

[sweep.train.max_grad_norm]
distribution = uniform
min = 0.0
mean = 1.0
max = 5.0
scale = auto

[sweep.train.bptt_horizon]
distribution = uniform_pow2
min = 4
max = 128
mean = 16
scale = auto

#[sweep.train.puf]
#distribution = logit_normal
#min = 0.01
#mean = 0.5
#max = 0.99
#scale = auto

[sweep.train.adam_beta1]
distribution = logit_normal
min = 0.5
mean = 0.9
max = 0.999
scale = auto

[sweep.train.adam_beta2]
distribution = logit_normal
min = 0.9
mean = 0.999
max = 0.99999
scale = auto

[sweep.train.adam_eps]
distribution = uniform
min = 0.00000000000001
mean = 0.00000001
max = 0.001
scale = auto

#[sweep.train.horizon]
#distribution = uniform_pow2
#min = 4
#max = 128
#mean = 32
#scale = 0.25

#[sweep.train.diayn_archive]
#distribution = uniform_pow2
#min = 2
#max = 64
#mean = 8
#scale = auto

#[sweep.train.diayn_loss_coef]
#distribution = uniform
#min = 0.0
#max = 2.0
#mean = 1.0
#scale = auto

#[sweep.train.diayn_coef]
#distribution = log_normal
#min = 0.0001
#mean = 0.1
#max = 0.99
#scale = auto
