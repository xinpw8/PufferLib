{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pwd\n",
    "%cd ../.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %env OMP_NUM_THREADS=1\n",
    "# %env OMP_NUM_THREADS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file_name = 'session_0398bd16_boey_base/poke_10485760_steps'\n",
    "file_name = r'D:\\pokered\\running\\session_f74031ee_env19_lr3e-4_ent01_bs2048_ep3_5120_vf05_v2_es2_fullrun_gamma96_ppo29_1058m\\poke_49152000_steps'\n",
    "run_cnt = 24\n",
    "ep_length_multiplier = 3_000  # how many k steps per episode\n",
    "# device = 'cpu'\n",
    "device = 'cuda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os.path import exists\n",
    "from pathlib import Path\n",
    "import uuid\n",
    "from baselines.boey_baselines2.red_gym_env import RedGymEnvV3 as RedGymEnv\n",
    "from stable_baselines3 import A2C, PPO\n",
    "from stable_baselines3.common import env_checker\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv, SubprocVecEnv\n",
    "from stable_baselines3.common.utils import set_random_seed\n",
    "from stable_baselines3.common.callbacks import CheckpointCallback\n",
    "import timeit\n",
    "\n",
    "def make_env(rank, env_conf, seed=0):\n",
    "    \"\"\"\n",
    "    Utility function for multiprocessed env.\n",
    "    :param env_id: (str) the environment ID\n",
    "    :param num_env: (int) the number of environments you wish to have in subprocesses\n",
    "    :param seed: (int) the initial seed for RNG\n",
    "    :param rank: (int) index of the subprocess\n",
    "    \"\"\"\n",
    "    def _init():\n",
    "        env_config['env_id'] = rank\n",
    "        env = RedGymEnv(env_conf)\n",
    "        env.reset(seed=(seed + rank))\n",
    "        return env\n",
    "    set_random_seed(seed)\n",
    "    return _init\n",
    "\n",
    "sess_path = Path(f'session_{str(uuid.uuid4())[:8]}session_3cf41181_env19_lr3e-4_ent01_bs2048_ep3_5120_vf05_v2_es2_fullrun_gamma96_ppo29_1.1b')\n",
    "ep_length = 1024 * ep_length_multiplier\n",
    "\n",
    "# state_dir = Path('../saved_states_v5')\n",
    "state_dir = Path(r'D:\\pokered\\states\\env19')\n",
    "env_config = {\n",
    "                'headless': True, 'save_final_state': True, \n",
    "                'early_stop': True,  # resumed early stopping to ensure reward signal\n",
    "                'action_freq': 24, 'init_state': 'has_pokedex_nballs_noanim.state', 'max_steps': ep_length, \n",
    "                # 'env_max_steps': env_max_steps,\n",
    "                'print_rewards': True, 'save_video': True, 'fast_video': True, 'session_path': sess_path,\n",
    "                'gb_path': 'PokemonRed.gb', 'debug': False, 'sim_frame_dist': 2_000_000.0, \n",
    "                'use_screen_explore': False, 'reward_scale': 4, \n",
    "                'extra_buttons': False, 'restricted_start_menu': False, \n",
    "                'noop_button': True,\n",
    "                'swap_button': True,\n",
    "                'enable_item_manager': True,\n",
    "                'level_reward_badge_scale': 1.0,\n",
    "                # 'randomize_first_ep_split_cnt': num_cpu,\n",
    "                # 'start_from_state_dir': state_dir, \n",
    "                # 'save_state_dir': state_dir,\n",
    "                'explore_weight': 1.5, # 3\n",
    "                'special_exploration_scale': 1.0,  # double the exploration for special maps (caverns)\n",
    "                'enable_stage_manager': True,\n",
    "                'enable_item_purchaser': True,\n",
    "                'auto_skip_anim': True,\n",
    "                'auto_skip_anim_frames': 8,\n",
    "                'early_stopping_min_reward': 2.0,\n",
    "                # 'total_envs': num_cpu,\n",
    "                'level_manager_eval_mode': True,\n",
    "        }\n",
    "\n",
    "num_cpu = 1 #64 #46  # Also sets the number of episodes per training iteration\n",
    "# envs = make_env(0, env_config)() #SubprocVecEnv([make_env(i, env_config) for i in range(num_cpu)])\n",
    "envs = SubprocVecEnv([make_env(i, env_config) for i in range(run_cnt)])\n",
    "# envs = DummyVecEnv([make_env(i, env_config) for i in range(run_cnt)])\n",
    "\n",
    "#env_checker.check_env(env)\n",
    "# file_name = 'session_bec9c90f/poke_45875200_steps'\n",
    "\n",
    "print('\\nloading checkpoint')\n",
    "model = PPO.load(file_name, env=envs, custom_objects={'lr_schedule': 0, 'clip_range': 0}, device=device)\n",
    "# model = PPO.load(file_name, env=envs, custom_objects={'lr_schedule': 0, 'clip_range': 0}, device=device)\n",
    "\n",
    "#keyboard.on_press_key(\"M\", toggle_agent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.policy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.n_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    print('a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_rewards = []\n",
    "obses = envs.reset()\n",
    "start = timeit.default_timer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1):\n",
    "    print(f'\\nrun {i}')\n",
    "    for cur_step in range(ep_length):\n",
    "        # action = 7 # pass action\n",
    "        action, _states = model.predict(obses, deterministic=False)\n",
    "        # print(f'step {cur_step}, action: {action}')\n",
    "        obses, rewards, terminated, info = envs.step(action)\n",
    "        all_rewards.append(rewards[0])\n",
    "        if cur_step and cur_step % 2000 == 0:\n",
    "            print(f'step {cur_step}, fps: {cur_step / (timeit.default_timer() - start):.2f}')\n",
    "            print(f'rewards sum: {sum(all_rewards)}, max: {max(all_rewards)}, min: {min(all_rewards)}')\n",
    "            all_rewards = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# call env reset to release the video writer handle\n",
    "envs.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_params = 0\n",
    "for name, parameter in model.policy.named_parameters():\n",
    "    if not parameter.requires_grad:\n",
    "        continue\n",
    "    param = parameter.numel()\n",
    "    print(name, param)\n",
    "    total_params+=param\n",
    "print(f'total params: {total_params}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pokered",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
